{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Check GPU Availability and Setup Home Directory**"
      ],
      "metadata": {
        "id": "2JVS8-I9Feaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4BG62apRJjsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('')"
      ],
      "metadata": {
        "id": "7i3bmv0pJuxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "zvea9J89Fktm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1609029e-005c-476f-e4c8-b9a3231cf90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 30 13:24:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "Ptj5D6i9Fn2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn"
      ],
      "metadata": {
        "id": "fCjcC5VgF5iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download dataset from Roboflow (Roof_type_OR_Roof_Materials)**"
      ],
      "metadata": {
        "id": "kGPZuY4EGVun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Your API Key\") #enter your own\n",
        "project = rf.workspace(\"\").project(\"\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "wE4G4QabGc4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train_Yolo**"
      ],
      "metadata": {
        "id": "Ema0B-x2epSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "wueIoGZ905Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "#object segmentation\n",
        "\n",
        "model = YOLO('yolov8m-seg.pt')\n",
        "\n",
        "results = model.train(data=f'{dataset.location}/data.yaml', epochs=100, batch=8)"
      ],
      "metadata": {
        "id": "C_bH-Bj7L_jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the best Performance Matrices**"
      ],
      "metadata": {
        "id": "nZnlQqGHNMGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Best Model for Inference**"
      ],
      "metadata": {
        "id": "GWIYBvHqAzzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(f'/{HOME}/runs/segment/train/weights/best.pt')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#/content/drive/MyDrive/NEWRMATAPR14/runs/segment/train7/weights/best.pt"
      ],
      "metadata": {
        "id": "g3O8uzp5NWL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(f\"Model saved at: {os.path.expanduser('~')}/runs/segment/train/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "oyTo_Nc4nCE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Image TIle Inference_Check**"
      ],
      "metadata": {
        "id": "NZ3YC8psxabg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from shapely.geometry import Polygon\n",
        "import os\n",
        "\n",
        "# --- PARAMETERS ---\n",
        "MODEL_PATH = f'/{HOME}/runs//best.pt'\n",
        "IMAGE_PATH = ''\n",
        "SIMPLIFY_TOLERANCE = 2.0  # adjust to prune more points\n",
        "\n",
        "# --- LOAD MODEL & IMAGE ---\n",
        "model = YOLO(MODEL_PATH)\n",
        "image = cv2.imread(IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "h, w = image.shape[:2]\n",
        "\n",
        "# --- RUN INFERENCE & SHOW (optional) ---\n",
        "results = model(image_rgb)[0]\n",
        "plt.imshow(results.plot())\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"\")\n",
        "plt.show()\n",
        "\n",
        "# --- PREPARE OUTPUT FILE ---\n",
        "base = os.path.splitext(os.path.basename(IMAGE_PATH))[0]\n",
        "out_txt = os.path.join('' + '.txt')\n",
        "\n",
        "with open(out_txt, 'w') as f:\n",
        "    if results.masks is None:\n",
        "        print(\"No masks found.\")\n",
        "    else:\n",
        "        for i, mask_xy in enumerate(results.masks.xy):\n",
        "            # simplify polygon\n",
        "            poly = Polygon(mask_xy)\n",
        "            poly_simple = poly.simplify(SIMPLIFY_TOLERANCE, preserve_topology=False)\n",
        "            coords = list(poly_simple.exterior.coords)[:-1]  # drop closing point\n",
        "\n",
        "            # normalize & flatten\n",
        "            norm = []\n",
        "            for x, y in coords:\n",
        "                norm.extend([x / w, y / h])\n",
        "\n",
        "            # class ID\n",
        "            cls_id = int(results.boxes.cls[i].item())\n",
        "            seg_line = f\"{cls_id} \" + \" \".join(f\"{c:.6f}\" for c in norm)\n",
        "\n",
        "            # write to file\n",
        "            f.write(seg_line + \"\\n\")\n",
        "\n",
        "print(f\"Saved simplified labels to: {out_txt}\")"
      ],
      "metadata": {
        "id": "7lsTSUzJ27EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Infer Multiple Image tiles and get the labels in .txt format to create shape files**"
      ],
      "metadata": {
        "id": "6VVGXqtZu5ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "# Define paths\n",
        "import os\n",
        "\n",
        "# Define base path\n",
        "base_path = 'r'\n",
        "\n",
        "# Define the images path (optional, as you're not appending anything here)\n",
        "images_path = os.path.join(base_path, '')  # This just equals base_path\n",
        "\n",
        "# Create a folder named 'labels' under base_path\n",
        "output_dir = os.path.join(base_path, 'labels')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Label directory created at: {output_dir}\")\n",
        "\n",
        "# Image size\n",
        "img_w, img_h = 640, 640\n",
        "\n",
        "# Get all image files\n",
        "image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "for img_name in image_files:\n",
        "    img_path = os.path.join(images_path, img_name)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        print(f\"⚠️ Could not load image: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = model(image_rgb)[0]\n",
        "\n",
        "    label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
        "    label_path = os.path.join(output_dir, label_name)\n",
        "\n",
        "    roboflow_labels = []\n",
        "    if results.masks is not None:\n",
        "        for i, polygon in enumerate(results.masks.xy):\n",
        "            class_id = int(results.boxes.cls[i].item())\n",
        "            coords = []\n",
        "            for x, y in polygon:\n",
        "                x_norm = round(x / img_w, 8)\n",
        "                y_norm = round(y / img_h, 8)\n",
        "                coords.append(f\"{x_norm} {y_norm}\")\n",
        "            label_line = f\"{class_id} \" + \" \".join(coords)\n",
        "            roboflow_labels.append(label_line)\n",
        "\n",
        "        with open(label_path, 'w') as f:\n",
        "            for line in roboflow_labels:\n",
        "                f.write(line + '\\n')\n",
        "\n",
        "        print(f\"✅ Saved: {label_path}\")\n",
        "    else:\n",
        "        print(f\"⚠️ No masks for: {img_name}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bakpzIhzF3gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create .shp files for GIS**"
      ],
      "metadata": {
        "id": "qCsGHRK_v1Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install Libraries (if running in Colab) ===\n",
        "!pip install geopandas shapely fiona\n",
        "\n",
        "# === Import Libraries ===\n",
        "import os\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "# === Editable Paths ===\n",
        "pgw_dir = \"\"      # Folder containing PGW files\n",
        "labels_dir = \"\"   # Folder containing YOLO label .txt files\n",
        "out_dir = \"\"  # Output folder for shapefiles\n",
        "\n",
        "# === Constants ===\n",
        "IMG_WIDTH =640      #  CHANGE HERE: Correct if labels were made on 1280x1280 images\n",
        "IMG_HEIGHT = 640     # CHANGE HERE: Correct if labels were made on 1280x1280 images\n",
        "crs_code = \"\"  # Coordinate reference system (example: GDA94 / MGA Zone 56 OR_ EPSG:28356)\n",
        "\n",
        "# === Class ID to Name Mapping for Roof types and Roof Material types ===\n",
        "class_map = {\n",
        "    \"0\": \"\",\n",
        "    \"1\": \"\",\n",
        "    \"2\": \"\",\n",
        "    \"3\": \"\"\n",
        "}\n",
        "\n",
        "# === Create Output Directory if It Doesn't Exist ===\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# === Function to Read PGW (World File) ===\n",
        "def read_world_file(pgw_path):\n",
        "    with open(pgw_path, \"r\") as f:\n",
        "        lines = f.read().strip().split()\n",
        "    A = float(lines[0])  # pixel width\n",
        "    D = float(lines[1])  # rotation about y-axis\n",
        "    B = float(lines[2])  # rotation about x-axis\n",
        "    E = float(lines[3])  # pixel height (usually negative)\n",
        "    C = float(lines[4])  # X center coordinate of top-left pixel\n",
        "    F = float(lines[5])  # Y center coordinate of top-left pixel\n",
        "    return A, B, D, E, C, F\n",
        "\n",
        "# === Main Loop: Process Each PGW and Matching Label File ===\n",
        "for pgw_file in os.listdir(pgw_dir):\n",
        "    if not pgw_file.lower().endswith(\".pgw\"):\n",
        "        continue\n",
        "\n",
        "    pgw_basename = os.path.splitext(pgw_file)[0]\n",
        "\n",
        "    # Find matching label file\n",
        "    found_label = None\n",
        "    for lf in os.listdir(labels_dir):\n",
        "        if pgw_basename in lf and lf.lower().endswith(\".txt\"):\n",
        "            found_label = lf\n",
        "            break\n",
        "\n",
        "    if not found_label:\n",
        "        print(f\"⚠️ No matching label file found for {pgw_file}\")\n",
        "        continue\n",
        "\n",
        "    # Get the label file base name (without .txt extension)\n",
        "    label_basename = os.path.splitext(found_label)[0]\n",
        "\n",
        "    # Read PGW transformation\n",
        "    pgw_path = os.path.join(pgw_dir, pgw_file)\n",
        "    A, B, D, E, C, F = read_world_file(pgw_path)\n",
        "\n",
        "    # Read label file\n",
        "    label_path = os.path.join(labels_dir, found_label)\n",
        "    all_polygons = []\n",
        "    all_classes = []\n",
        "\n",
        "    with open(label_path, \"r\") as lf:\n",
        "        for line in lf:\n",
        "            vals = line.strip().split()\n",
        "            if len(vals) < 3:\n",
        "                continue\n",
        "\n",
        "            class_id = vals[0]\n",
        "            coords = [float(x) for x in vals[1:]]\n",
        "            points_normalized = list(zip(coords[0::2], coords[1::2]))\n",
        "\n",
        "            polygon_pts = []\n",
        "            for (nx, ny) in points_normalized:\n",
        "                # Scale normalized (0–1) coordinates to 640x640 pixel space\n",
        "                px = nx * IMG_WIDTH\n",
        "                py = ny * IMG_HEIGHT\n",
        "\n",
        "                # Apply affine transformation to map coordinates\n",
        "                mapX = C + A * px + B * py\n",
        "                mapY = F + D * px + E * py\n",
        "                polygon_pts.append((mapX, mapY))\n",
        "\n",
        "            polygon_geom = Polygon(polygon_pts)\n",
        "\n",
        "            # OPTIONAL: Fix invalid polygons\n",
        "            if not polygon_geom.is_valid:\n",
        "                polygon_geom = polygon_geom.buffer(0)\n",
        "\n",
        "            all_polygons.append(polygon_geom)\n",
        "            all_classes.append(class_id)\n",
        "\n",
        "    # Map Class IDs to Names\n",
        "    all_class_names = [class_map.get(cid, \"Unclassified\") for cid in all_classes]\n",
        "\n",
        "    # Build GeoDataFrame\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        {\n",
        "            \"class_id\": all_classes,\n",
        "            \"class_name\": all_class_names,\n",
        "            \"geometry\": all_polygons\n",
        "        },\n",
        "        crs=crs_code\n",
        "    )\n",
        "\n",
        "    # Save Shapefile using label basename\n",
        "    out_shp_path = os.path.join(out_dir, f\"{label_basename}.shp\")\n",
        "    gdf.to_file(out_shp_path)\n",
        "    print(f\"✅ Created Shapefile: {out_shp_path}\")\n"
      ],
      "metadata": {
        "id": "u5bbrQ41v7Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd0d4ea-e78b-4e63-cc19-1a1c940bfc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona) (2025.4.26)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (8.2.0)\n",
            "Collecting click-plugins>=1.0 (from fiona)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count the numbers .shp files**"
      ],
      "metadata": {
        "id": "7v13mq-Fw0yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set your folder path where shapefiles are located\n",
        "search_folder = \"\"  # <-- Change this\n",
        "\n",
        "# Initialize counter\n",
        "shp_file_count = 0\n",
        "\n",
        "# Walk through all subdirectories\n",
        "for root, dirs, files in os.walk(search_folder):\n",
        "    for file in files:\n",
        "        if file.lower().endswith('.shp'):\n",
        "            shp_file_count += 1\n",
        "\n",
        "print(f\"Total number of .shp files: {shp_file_count}\")"
      ],
      "metadata": {
        "id": "6f0d_K9Dw2L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge All .shp files into One for GIS**"
      ],
      "metadata": {
        "id": "CcnS1CWKw4a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Set your input folder where all the shapefiles are located\n",
        "input_folder = \"\"\n",
        "\n",
        "# 2. Set your output folder where you want to save the combined shapefile\n",
        "output_folder = \"\"\n",
        "output_filename = \"Roof_Type_OR_Materials_combined_shapefile.shp\"  # Output shapefile name\n",
        "\n",
        "# 3. Make sure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 4. List all .shp files\n",
        "shapefile_list = []\n",
        "for root, dirs, files in os.walk(input_folder):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(\".shp\"):\n",
        "            shapefile_list.append(os.path.join(root, file))\n",
        "\n",
        "# 5. Read and combine all shapefiles\n",
        "gdf_list = [gpd.read_file(shp) for shp in shapefile_list]\n",
        "\n",
        "# 6. Concatenate into one GeoDataFrame\n",
        "combined_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
        "\n",
        "# 7. Save the combined shapefile to the output folder\n",
        "output_path = os.path.join(output_folder, output_filename)\n",
        "combined_gdf.to_file(output_path)\n",
        "\n",
        "print(f\"✅ Successfully combined {len(shapefile_list)} shapefiles into {output_path}\")"
      ],
      "metadata": {
        "id": "_T-txFS_w9sv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}